<head>


        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <!--   <meta name="viewport" content="width=device-width, initial-scale=0, maximum-scale=1, user-scalable=yes,shrink-to-fit=no"> -->
    <!--<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">-->
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-111471287-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-111471287-1');
</script>

<title>Di Wang's Homepage</title>

<style>


.main {
   /<sup>*</sup> Same width as the sidebar + right position in px <sup>*</sup>/
    padding: 20px 80px;
}


</style>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
</script>
<script type="text/javascript"
  src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!--########################### 
Expand/Collapse JS and CSS code for use 
in the HEAD section of your document.
Written by Dick Ervasti. Learn More at:
http://dickervasti.com/wiki-style-text-expand-collapse-no-jquery.htm
##################################-->
<script type="text/javascript">
<!--
    function expand_collapse(id) {
       var e = document.getElementById(id);
       var f = document.getElementById(id+"_arrows");
       if(e.style.display == 'none'){
          e.style.display = 'block';
          f.innerHTML = '&#9650';
       }
       else {
          e.style.display = 'none';
          f.innerHTML = '&#9660';
       }
    }
//-->
</script>
<style type="text/css">
.arrows{text-decoration:none;color:silver;}
</style>
</head>



<div class="main">
<h1 style="text-align: center;"><i>Di Wang's Homepage
</i></h1>
Chinese: 王帝<br/>
Al Khawarizmi Building 1, Room 4341 <br/>
Division of CEMSE
<br/>King Abdullah University of Science and Technology<br/>
Thuwal, Saudi Arabia, 23955-6900<br/>
<b>Email</b> : <i>di.wang@kaust.edu.sa</i><br/>
<b>Tel:</b> <i>+966 (012) 8080645</i>
<br/>  
<hr>
<h3><a name="bio">Short Bio</a></h3>
<p> 
     <img src="diwang.jpg" alt="" style="float:left; height:190px; margin:10px; width:130px" > 
     I am currently an Assistant Professor of Computer Science in the Division of Computer, Electrical and Mathematical Sciences and Engineering (CEMSE) at the King Abdullah University of Science and Technology (KAUST). And I am also the PI of <a href="https://cemse.kaust.edu.sa/part"> Privacy-Awareness, Responsibility and Trustworthy (PART) Lab </a>. 
    Before that, I got my Ph.D degree in Computer Science at <a href="
    https://www.buffalo.edu/">
    The State University of New York (SUNY) at Buffalo</a> under supervision of <a href="
    https://www.cse.buffalo.edu//~jinhui/"> Dr. Jinhui Xu </a>. Before my Ph.D study I got 
    my Master degree in Mathematics at <a href="http://www.uwo.ca/">
     University of Western Ontario</a> in 2015, and I got my Bachelor degree in Mathematics and Applied
    Mathematics at <a href="http://www.sdu.edu.cn/">Shandong University</a> in 2014.</br> </br>
    
    My most recent resume (last updated in December, 2020) can be found <a href="cv_web.pdf">here</a>. 

    <p>
        Dissertation: <a href="papers/Dissertation.pdf">Some Fundamental Machine Learning Problems in the Differential Privacy Model</a>. 
    </p>



     <p style="color:red;"><strong>
         Current Openings:</strong> I am always looking for several Postdocs, PhD students, internship and visiting students (all are fully funded). If you are interested
       in working with me, feel free to send me your CV and transcripts. See <a href="PhD.html">PhD</a>  and <a href="Postdoc.html">Postdoc</a> for details. 
    </p>
</p>



<hr>
<h3><a name="area">Research Interests</a></h3>
<li> <strong>Private Data Analytics</strong>: Differential privacy, privacy-preserving machine learning/data mining and  privacy attack in machine learning </li> </br>
<li> <strong>Trustworthy Machine Learning</strong>: Robust statistics/estimation,  interpretable machine learning, fairness in machine learning, adversarial machine learning </li></br>
<li> <strong>Statistical Learning Theory</strong>: high dimensional statistics, causal inference, statistical estimation,  learning theory and quantum machine learning </li></br>
<li><strong> Healthcare</strong>: Trustworthy issues in digital healthcare, biomedical imaging and bioinformatics</li></br>



<hr>
<h3> <a name="prof">Professional Experience</a> </h3>
<ul>
<li> Spring 2019: Visiting Graduate Student,  <a href="https://simons.berkeley.edu/programs/privacy2019">Data Privacy: Foundations and Applications</a>, Simons Institute for the Theory of Computing,  University of California, Berkeley. </li></br>
<li> Summer 2018: Graduate Research Intern, <a href="https://privacytools.seas.harvard.edu/">Harvard University Privacy Tools Project</a>, Harvard University and Boston University, Mentor: <a href="http://www.cse.psu.edu/~ads22/">Adam Smith</a>. </li></br>

</ul>
<hr>

<h3> PhD Advisees</h3>
<ul>
<li>Zihang Xiang (CS PhD), 01/2021-</li> </br>
<li>Lijie Hu (CS PhD), 01/2021-</li> </br>
<li>Yulian Wu (CS PhD), 09/2021- </li> </br>
<li>Chenglong Wang (CS PhD), 09/201- </li></br>
</ul>


<hr>
<h3> <a name="manu">Manuscripts</a>   </h3>
(<span>&#9733;</span> my Master/PhD/Intern/Visiting students)
<ol>
    <!---
    <li><i>

    (In Preparation) Estimating Smooth GLM in Non-interactive LDP Model with Public Unlabeled Data for Gaussian Unput.</i><a href="papers/ISIT21_ERM.pdf"><img src="pdf_icon.gif" class="smallpadleft"/></a> Abstract<a href="#ISIT20212_GLM" id="37_arrows" class="arrows" onclick="expand_collapse('37');">&#9660</a>
    <div id="37" style="display:none;"><p> 



    </p></div> </br> <strong>Di Wang</strong>. </br>
</li>
</br> 

     
    -->
    <li><i>
        One-shot Private Fair Learning: From Exponential to Quasi-polynomial Sample Complexity.</i><a href="papers/MSML2021_Fair.pdf"><img src="pdf_icon.gif" class="smallpadleft"/></a> Abstract<a href="#MSML2021_Fair" id="36_arrows" class="arrows" onclick="expand_collapse('36');">&#9660</a>
    <div id="36" style="display:none;"><p> 



    </p></div> </br> <strong>Di Wang</strong>. </br>
</li>

</br> 
    <li><i>
        On Facility Location Problem in the Central and Local Differential Privacy Model.</i><a href="papers/nips21.pdf"><img src="pdf_icon.gif" class="smallpadleft"/></a> Abstract<a href="#NIPS2021" id="38_arrows" class="arrows" onclick="expand_collapse('38');">&#9660</a>
    <div id="38" style="display:none;"><p> 
        We revisit the facility location problem in the differential privacy (DP) model and solve several open problems proposed by previous work. In the first part we focus on the problem in the central $\epsilon$-DP model. Under the hierarchically well-separated tree (HST) metric and the super-set output setting, \citet{prev2019} showed a lower bound of $\Omega(\frac{1}{\sqrt{\epsilon}})$  on the approximation ratio, and an algorithm achieving $O(\frac{1}{\epsilon})$ approximation in the case of uniform facility cost.  %improve over these results by closing the gap between the upper and lower bound, {\em i.e.,} 
        In this paper, we show that there is an $\epsilon$-DP algorithm with $O(\frac{1}{\sqrt{\epsilon}})$ approximation ratio for the general non-uniform facility cost setting. So, not only our result closes the gap between the upper and lower bounds, but also it extends the result of \citeauthor{prev2019} to the non-uniform case.
        
        In the second part of the paper, we focus on the problem in the local DP (LDP) model. In the problem, whether a client participates in the facility location instance is the private information that needs to be protected. Under the HST metric, we show that there is a non-interactive algorithm achieving $O(\frac{N^{\frac{1}{4}}}{\epsilon^2})$ approximation ratio, where $N$ is the size of the metric. On the negative side, we show a lower bound of $\Omega(\frac{N^{\frac{1}{4}}}{\sqrt{\epsilon}})$ on the approximation ratio for any non-interactive $\epsilon$-LDP algorithm. So our ratio is tight in terms of $N$.
    </p></div> </br>[<strong>alphabetic order</strong>]  <strong>Yunus Esencayi</strong>,  <strong>Marco Gaboardi</strong>, <strong>Shi Li</strong> and <strong>Di Wang</strong>  </br>
</li>
</br>
<li><i>Differentially Private Pairwise Learning Revisited.</i><a href="papers/DASFAA_pairwise.pdf"><img src="pdf_icon.gif" class="smallpadleft"/></a> Abstract<a href="#DASFAA_pairwise" id="35_arrows" class="arrows" onclick="expand_collapse('35');">&#9660</a>
    <div id="35" style="display:none;"><p>  
            Instead of learning with pointwise loss functions, learning with pairwise loss functions (pairwise learning) has received much attention recently as it is more capable of modeling the relative relationship between pairs of samples.   However, most of the existing algorithms for pairwise learning fail to take into consideration the privacy issue in their design.  To address this  issue, previous work studied pairwise learning in the Differential Privacy (DP) model. However, their utilities (population errors) are far from optimal. To address the sub-optimal utility issue, in this paper, we proposed new $(\epsilon, \delta)$ or $\epsilon$-DP algorithms for pairwise learning. Specifically, when the loss functions are Lipschitz, smooth and strongly convex, we show that the output of our algorithm achieves an expected population error of $O(\frac{1}{n}+\frac{d\log\frac{1}{\delta}}{n^2\epsilon^2})$ and $O(\frac{1}{n}+\frac{d^2}{n^2\epsilon^2})$ for $(\epsilon, \delta)$-DP and $\epsilon$-DP, respectively, where $n$ is the sample size and $d$ is the dimension of the underlying space. 
            Moreover, for general convex case,  the output of our algorithm achieves an expected population error  of $O(\frac{1}{\sqrt{n}}+\frac{\sqrt{d \log\frac{1}{\delta}}}{n\epsilon})$ and $O(\frac{1}{\sqrt{n}}+\frac{d}{n\epsilon})$ for $(\epsilon, \delta)$-DP and $\epsilon$-DP, respectively. It is also notable that these upper bounds are {\bf optimal} ({\em i.e.,} match the lower bounds). We also conduct extensive experiments on real-world datasets to evaluate the proposed algorithms, experimental results support our theoretical analysis and show the priority of our algorithms. 
</br>    
    </p></div> </br> Zhiyu Xue<sup>*</sup><sup><span>&#9733;</span></sup>, Shaoyang Yang<sup>*</sup><sup><span>&#9733;</span></sup>, Mengdi Huai and <u><strong>Di Wang</strong></u>. (* equal contribution) </br>

</li>
</br> 
        <li><i>
                Differentially Private (Gradient) Expectation Maximization Algorithm with Statistical Guarantees.</i><a href="papers/UAI2021_EM.pdf"><img src="pdf_icon.gif" class="smallpadleft"/></a> Abstract<a href="#AAAI2021_EM" id="34_arrows" class="arrows" onclick="expand_collapse('34');">&#9660</a>
            <div id="34" style="display:none;"><p> 
                    As one popular technique for estimating the maximum likelihood 
                    of mixture models or incomplete data problems, (Gradient) Expectation Maximization (EM) algorithm presents a challenge for preserving privacy of sensitive data. While although there are already some Differentially Private (DP) variants of (Gradient) EM algorithm, however, unlike in the non-private case, there is still no finite sample statistical guarantees. To address this issue, in this paper we propose the first DP variant of (Gradient) EM algorithm with statistical guarantees.  Moreover, we apply our general framework to three canonical models: Gaussian Mixture Model (GMM), Mixture of Regressions Model (MRM) and Linear Regression with Missing Covariates (RMC). Specifically, for GMM in the DP model, our estimation error is near optimal in some cases. And for other two models in the DP model, we provide the first finite sample statistical guarantees.  Our theory is supported by thorough numerical results. 
            </p></div> </br> <strong>Di Wang<sup>*</sup></strong>, <a href="https://dblp.uni-trier.de/pers/hd/d/Ding:Jiahao"><strong>Jiahao Ding</strong></a><sup>*</sup>, Zejun Xie<sup><span>&#9733;</span></sup>, <a href="http://www2.egr.uh.edu/~mpan2/">Miao Pan</a> and Jinhui Xu (* equal contribution). </br>
        </li>
    </br>

        <li><i>Towards Assessment of Randomized Mechanisms for
            Certifying Adversarial Robustness.</i><a href="papers/NeurIPS2020_RandomSmoothing.pdf"><img src="pdf_icon.gif" class="smallpadleft"/></a> Abstract<a href="#NIPS2020_random" id="28_arrows" class="arrows" onclick="expand_collapse('28');">&#9660</a>
            <div id="28" style="display:none;"><p> 
                As a certified defensive technique, randomized smoothing has received considerable attention due to its scalability to large datasets and neural networks. However, several important questions remain unanswered, such as (i) whether the Gaussian mechanism is an appropriate option for certifying $\ell_2$-norm robustness, and (ii) whether there is an appropriate randomized mechanism to certify $\ell_\infty$-norm robustness 
                for high-dimensional datasets. To shed light on these questions, the main difficulty is how to assess each randomized mechanism. In this paper, we propose a generic framework, which connects the existing frameworks in (Lecuyer et al. 2018; Li et al. 2019), to assess randomized mechanisms. 
                Under our framework, for a mechanism which can certify a certain extent of robustness, we define the magnitude ({\em i.e.,} the expected $\ell_\infty$ norm) of the randomized noise it adds as the metric for assessing its appropriateness. We also derive lower bounds on the metric for $\ell_2$-norm and $\ell_\infty$-norm cases as the criteria for assessment.
                Based on our framework, we assess the Gaussian and Exponential mechanisms by comparing the magnitude of noise added by these mechanisms and the corresponding criteria. We first conclude that the Gaussian mechanism is an appropriate option to certify $\ell_2$-norm robustness. Moreover, surprisingly, we also show that the Gaussian mechanism is also an appropriate option for certifying $\ell_\infty$-norm robustness, instead of the Exponential mechanism.
                Finally, we verify our theoretical results by evaluations on CIFAR10 and ImageNet. 
            </p></div> </br> <a href="https://scholar.google.com/citations?user=DDP03z4AAAAJ&hl=en"><strong>Tianhang Zheng</strong></a><sup>*</sup>, <strong>Di Wang<sup>*</sup></strong>, <a href="https://iqua.ece.toronto.edu/bli/">Baochun Li</a> and Jinhui Xu (* equal contribution). </br>
        </li>

    </br>


 


</ol>




</ol>
<hr>
<h3> <a name="pubs_con">Selected Publications</a> [<a href="Publication.html">Full List</a>] [<a  href="https://scholar.google.com/citations?user=5hGRe_QAAAAJ&hl=en&authuser=1&oi=sra">Google Scholar</a>] [<a href="https://dblp.uni-trier.de/pid/18/5410-15.html">DBLP</a>] </h3> 
<ol>
    <li> <i>On Sparse Linear Regression in the Local Differential Privacy Model.</i> <a href="papers/TIT2020_regression.pdf"><img src="pdf_icon.gif" class="smallpadleft"/></a> Abstract<a href="#TIT2020_regression" id="20_arrows" class="arrows" onclick="expand_collapse('20');">&#9660</a>
        <div id="20" style="display:none;"><p> In this paper, we study the sparse linear regression problem in the Local Differential Privacy (LDP) model. We first show that polynomial dependency on the dimensionality $p$ of the space is unavoidable for the estimation error in both non-interactive and sequential interactive local models, if the privacy of the whole dataset needs to be preserved.  Similar limitations also exist for other types of error measurements and in the relaxed local models. This indicates that differential privacy in high dimensional space is unlikely achievable for the problem. With the understanding of this limitation, we then present two algorithmic results. The first one is 
                a sequential interactive LDP algorithm for the low dimensional sparse case, called Locally Differentially Private Iterative Hard Thresholding (LDP-IHT), which achieves a near optimal upper bound. This algorithm is actually rather general and can be used to solve quite a few other problems, such as (Local) DP-ERM with sparsity constraints and sparse regression with non-linear measurements.  The second one is for the restricted (high dimensional) case where only  the privacy  of the responses (labels) needs to be preserved. For this case, 
                we show that the optimal rate of the error estimation can be made logarithmically depending on $p$ (i.e., $\log p$) in the local model, 
                where an upper bound is obtained by a label-privacy version of LDP-IHT. Experiments on real world and synthetic datasets confirm our theoretical analysis.
        </p></div> </br> <strong>Di Wang</strong> and Jinhui Xu. </br>
        IEEE Transactions on Information Theory, Volume 67, no. 2, Pages 1182-1200, Feb. 2021. </br>
    </li>
</br>
    <li> <i>Empirical Risk Minimization in the Non-interactive Local
        Model of Differential Privacy.</i> <a href="papers/JMLR2020_LDPERM.pdf"><img src="pdf_icon.gif" class="smallpadleft"/></a> [<a href="https://www.jmlr.org/papers/v21/19-253.html">Link</a>] Abstract<a href="#JMLR2020_LDPERM" id="16_arrows" class="arrows" onclick="expand_collapse('16');">&#9660</a>
        <div id="16" style="display:none;"><p> In this paper, we study the Empirical Risk Minimization (ERM) problem in the non-interactive Local Differential Privacy (LDP) model.  We first show that if the loss function is $(\infty, T)$-smooth, by using the Bernstein polynomial approximation we can avoid a dependency of the  sample complexity, to achieve error $\alpha$, on the exponential of the dimensionality $p$ with base $1/\alpha$  (i.e., $\alpha^{-p}$).
            This answers a question from (Smith et.al., 2017).   Then, we propose player-efficient algorithms with $1$-bit communication complexity and $O(1)$ computation cost for each player. The error bound of these algorithms is asymptotically the same as the original one. With some additional assumptions, we also give an algorithm which is more efficient for the server. Based on different types of polynomial approximations, we propose (efficient) non-interactive locally differential private algorithms for learning the set of k-way marginal queries and the set of smooth queries. Moreover, we study the case of  $1$-Lipschitz generalized linear convex loss functions and show that there is an $(\epsilon, \delta)$-LDP algorithm whose sample complexity for achieving error $\alpha$ is only linear in the dimensionality $p$ and quasi-polynomial in other terms. To prove this, we first show that the conclusion holds for the hinge loss function. Then, we extend the result to any $1$-Lipschitz generalized linear convex loss functions by showing that every such a function can be approximated by a linear combination of hinge loss functions and some linear functions. Our results use a polynomial of inner product approximation technique. Then we apply our technique to the Euclidean median problem and show that its sample complexity needs only to be quasi-polynomial in $p$, which is the first result with a sub-exponential sample complexity in $p$ for non-generalized linear loss functions. 

            
        </p></div> </br> <strong>Di Wang</strong>, Marco Gaboardi,  Adam Smith and  Jinhui Xu. </br>
        Journal of Machine Learning Research, Volume 21, 200 (2020), Pages 1-39.
        
        </li>
    </br>
    <li><i>Robust High Dimensional Expectation Maximization Algorithm via Trimmed Hard Thresholding.</i><a href="papers/MLJ2020_RobustEM.pdf"><img src="pdf_icon.gif" class="smallpadleft"/></a> [<a href="https://link.springer.com/article/10.1007/s10994-020-05926-z">Link</a>] Abstract<a href="#MLJ2020_RobustEM" id="21_arrows" class="arrows" onclick="expand_collapse('21');">&#9660</a>
        <div id="21" style="display:none;"><p> In this paper, we study the problem of estimating latent variable models with arbitrarily corrupted samples in the high dimensional case, i.e., $d\gg n$, where the underlying parameter is sparse. Specifically, we propose a method called Trimmed (Gradient) Expectation Maximization which attaches a trimming gradients and hard thresholding step to the  Expectation step (E-step) and  Maximization step (M-step), respectively. Particularly, under some mild assumptions, with an appropriate initialization, we show that the algorithm is corruption-free and converges to the (near) optimal statistical rate geometrically when the fraction of corruption samples satisfies $\alpha\leq O(\frac{1}{\sqrt{n}})$. Moreover, we implement our general framework to three canonical examples: mixture of Gaussians, mixture of regressions and linear regression with missing covariates. Experiments also support our theoretical analysis.  

            
        </p></div> </br> <strong>Di Wang<sup>*</sup></strong>, <strong>Xiangyu Guo<sup>*</sup></strong>, Shi Li and Jinhui Xu (* equal contribution). </br>
       Machine Learning, 109, 2283-2311 (2020). </br> 

    </li>
</br>        
<li><i>Estimating Smooth GLM in Non-interactive Local Differential Privacy Model with Public Unlabeled Data.</i><a href="papers/NeurIPS2020_GLM.pdf"><img src="pdf_icon.gif" class="smallpadleft"/></a> Abstract<a href="#NIPS2020_glms" id="22_arrows" class="arrows" onclick="expand_collapse('22');">&#9660</a>
    <div id="22" style="display:none;"><p>  
vol. 67, no. 2, pp. 1182-1200, Feb. 2021
        In this paper, we study the problem of estimating smooth Generalized Linear Models (GLM) in the Non-interactive Local Differential Privacy (NLDP) model. 
Different from its classical setting, our model allows the server to process 
some additional public but unlabeled data. 
We first show that there is an $(\epsilon, \delta)$-NLDP algorithm for 
GLM (under some mild assumptions), if each data record is i.i.d sampled from some sub-Gaussian distribution with bounded $\ell_1$-norm. 
The sample complexity of both 
public and private data, for the algorithm to achieve an  $\alpha$  estimation error (in $\ell_\infty$-norm), is $\tilde{O}(p^2\alpha^{-2}\epsilon^{-2})$ if $\alpha$ is not too small (i.e., $\alpha\geq \Omega(\frac{1}{\sqrt{p}})$), where $p$ is the dimensionality of the data. This is a significant improvement over the previously known quasi-polynomial (in $\alpha$) or exponential (in $p$) complexity  of convex GLM with no public data.
We then extend our idea to the non-linear regression problem and show 
a similar phenomenon for it.
Finally, we demonstrate the practicality of our algorithms through experiments on both synthethic and real world datasets. 
To our best knowledge, this is the first paper showing the existence of efficient and practical 
algorithms for GLM and non-linear regression 
in the NLDP model with public unlabeled data.
</br>    
    </p></div> </br> <strong>Di Wang<sup>*</sup></strong>,  <a href="https://huanyuzhang.github.io/"><strong>Huanyu Zhang</strong></a><sup>*</sup>, Marco Gaboardi and Jinhui Xu. (* equal contribution) </br>
    The 32nd International Conference on Algorithmic Learning Theory (ALT 2021).
</li>
</br>  
    <li><i>On Differentially Private Stochastic Convex Optimization with Heavy-tailed Data.</i><a href="papers/ICML2020_DPSCO.pdf"><img src="pdf_icon.gif" class="smallpadleft"/></a> Abstract<a href="#ICML2020_heavy" id="27_arrows" class="arrows" onclick="expand_collapse('27');">&#9660</a>
        <div id="27" style="display:none;"><p> 
            In this paper, we consider the problem of designing Differentially Private (DP) algorithms for Stochastic Convex Optimization (SCO) on heavy-tailed data. The irregularity of such data violates some key assumptions used in almost all existing DP-SCO and DP-ERM methods, resulting in failure to provide the DP guarantees. To better understand this type of challenges, we provide in this paper a comprehensive study of DP-SCO under various settings. First, we consider the case where the loss function is strongly convex and smooth. For this case, we propose a method based on the sample-and-aggregate framework, which has an excess population risk of $\tilde{O}(\frac{d^3}{n\epsilon^4})$ (after omitting other factors), where $n$ is the sample size and $d$ is the dimensionality of the data. Then, we show that with some additional assumptions on the loss functions, it is possible to reduce the \textit{expected} excess population risk to $\tilde{O}(\frac{ d^2}{ n\epsilon^2 })$. To lift these additional conditions, we also provide a gradient smoothing and trimming based scheme to achieve excess population risks of $\tilde{O}(\frac{ d^2}{n\epsilon^2})$ and $\tilde{O}(\frac{d^\frac{2}{3}}{(n\epsilon^2)^\frac{1}{3}})$ for strongly convex and general convex loss functions, respectively, \textit{with high probability}. Experiments on both synthetic and real-world datasets suggest that our algorithms can effectively deal with the challenges caused by data irregularity.
        </p></div> </br> <strong>Di Wang<sup>*</sup></strong>, <a href="https://dblp.org/pers/x/Xiao:Hanshen.html"><strong>Hanshen Xiao</strong></a><sup>*</sup>, <a href="https://people.csail.mit.edu/devadas/">Srini Devadas</a> and Jinhui Xu (* equal contribution). </br>
        The 37th International Conference on Machine Learning (ICML 2020).
    </li>
</br>
<li><i>Facility Location Problem in Differential Privacy Model Revisited.</i><a href="papers/NeurIPS2019_facility.pdf"><img src="pdf_icon.gif" class="smallpadleft"/></a> [<a href="http://papers.nips.cc/paper/9056-facility-location-problem-in-differential-privacy-model-revisited">Link</a>] Abstract<a href="#NeurIPS2019_facility" id="23_arrows" class="arrows" onclick="expand_collapse('23');">&#9660</a>
    <div id="23" style="display:none;"><p> 
        In this paper we study the uncapacitated facility location problem in the
        model of differential privacy (DP) with uniform facility
        cost. Specifically, we first show that, under the \emph{hierarchically well-separated tree (HST) metrics} and the super-set output setting that was introduced in (Gupta et al 2010), there is an $\epsilon$-DP
        algorithm that achieves an $O(\frac{1}{\epsilon})$
        (expected multiplicative) approximation ratio; this implies an
        $O(\frac{\log n}{\epsilon})$
        approximation ratio for the general metric case, where $n$ is the size of the input metric. These bounds improve
        the best-known results given by (Gupta et al 2010).  In particular, our approximation ratio for HST-metrics is independent of $n$, and the ratio for general metrics is independent of the aspect ratio of the input metric. On the negative side, we show that the approximation ratio of any $\epsilon$-DP algorithm is lower bounded by $\Omega(\frac{1}{\sqrt{\epsilon}})$, even for instances on HST metrics with uniform facility cost, under the super-set output setting. The lower bound shows that the dependence of the approximation ratio for HST metrics on $\epsilon$ can not be removed or greatly improved. Our novel methods and techniques for both the upper and lower bound may find additional applications.
    </p></div> </br>[<strong>alphabetic order</strong>] <a href="https://www.acsu.buffalo.edu/~yunusese/"> <strong>Yunus Esencayi</strong></a>,  <strong>Marco Gaboardi</strong>, <a href="https://cse.buffalo.edu/~shil/"><strong>Shi Li</strong></a> and <strong>Di Wang</strong>  </br>

    Conference on Neural Information Processing Systems (NIPS/NeurIPS), 2019.
</li>

    </br>

    <li><i>Differentially Private Empirical Risk Minimization with Non-convex Loss Functions.</i><a href="papers/ICML2019_nonconvex.pdf"><img src="pdf_icon.gif" class="smallpadleft"/></a> [<a href="http://proceedings.mlr.press/v97/wang19c.html">Link</a>] Abstract<a href="#ICML2019_nonconvex" id="10_arrows" class="arrows" onclick="expand_collapse('10');">&#9660</a>
        <div id="10" style="display:none;"><p> 
                We study the problem of Empirical Risk Minimization (ERM) with (smooth) non-convex loss functions under the differential-privacy (DP) model. Existing approaches for this problem mainly adopt gradient norms to measure the error, which in general cannot guarantee the quality of the solution. To address this issue, 
                we first study the expected excess empirical (or population) risk, which was primarily used as the utility to measure the quality for convex loss functions. Specifically, we show that
                the excess empirical (or population) risk can be upper bounded by $\tilde{O}(\frac{d\log (1/\delta)}{\log n\epsilon^2})$ in the $(\epsilon, \delta)$-DP settings, where $n$ is the data size and $d$ is the dimensionality of the space. 
                The $\frac{1}{\log n}$ term in the empirical risk bound can be further improved to $\frac{1}{n^{\Omega(1)}}$ (when $d$ is a constant) by a highly non-trivial analysis on the time-average error. 
                To obtain more efficient solutions, we also consider the connection between achieving differential privacy and finding approximate local minimum. 
                Particularly, we show that when the size $n$ is large enough, there are $(\epsilon, \delta)$-DP algorithms which can find an approximate local minimum of the empirical risk with high probability in both the constrained and non-constrained settings. 
                These results indicate that one can escape saddle points privately.
        </p></div> </br> <strong>Di Wang</strong>, <a href="https://cse.buffalo.edu/~changyou/">Changyou Chen</a> and  Jinhui Xu. </br>
        The 36th International Conference on Machine Learning (ICML 2019).
        </li>
        </br>
        <li> <i>On Sparse Linear Regression in the Local Differential Privacy Model.</i> <a href="papers/ICML2019_regression.pdf"><img src="pdf_icon.gif" class="smallpadleft"/></a> [<a href="http://proceedings.mlr.press/v97/wang19m.html">Link</a>] Abstract<a href="#ICML2019_regression" id="9_arrows" class="arrows" onclick="expand_collapse('9');">&#9660</a>
            <div id="9" style="display:none;"><p> In this paper, we study the sparse linear regression problem under the Local Differential Privacy (LDP) model. We first show that polynomial dependency on the dimensionality $p$ of the space is unavoidable for the estimation error in both non-interactive and sequential interactive local models, if the privacy of the whole dataset needs to be preserved.  Similar limitations also exist for other types of error measurements and in the relaxed local models. This indicates that differential privacy in high dimensional space is unlikely achievable for the problem. With the understanding of this limitation, we then present two algorithmic results. The first one is 
                a sequential interactive LDP algorithm for the low dimensional sparse case, called Locally Differentially Private Iterative Hard Thresholding (LDP-IHT), which achieves a near optimal upper bound. This algorithm is actually rather general and can be used to solve quite a few other problems, such as (Local) DP-ERM with sparsity constraints and sparse regression with non-linear measurements.  The second one is for the restricted (high dimensional) case where only  the privacy  of the responses (labels) needs to be preserved. For this case, 
                we show that the optimal rate of the error estimation can be made logarithmically depending on $p$ (i.e., $\log p$) in the local model, 
                where an upper bound is obtained by a label-privacy version of LDP-IHT. Experiments on real world and synthetic datasets confirm our theoretical analysis. 
            </p></div> </br> <strong>Di Wang</strong> and  Jinhui Xu.  </br> 
           The 36th International Conference on Machine Learning (ICML 2019). </br>
            <strong>Selected as Long Talk(Acceptance Rate: 140/3424= 4.1%) </strong>.
       
            </li>
        </br>
        <li> <i> Noninteractive Locally Private Learning of Linear Models via Polynomial Approximations.</i> <a href="papers/ALT2019_NLDP.pdf"><img src="pdf_icon.gif" class="smallpadleft"/></a> [<a href="http://proceedings.mlr.press/v98/wang19c.html">Link</a>] Abstract<a href="#ALT2019_NLDP" id="7_arrows" class="arrows" onclick="expand_collapse('7');">&#9660</a>
            <div id="7" style="display:none;"><p>In this paper, we study the Empirical Risk Minimization problem in the non-interactive Local Differential Privacy (LDP) model. First, we show that for the hinge loss function, there is an $(\epsilon, \delta)$-LDP algorithm whose sample complexity for achieving an error of $\alpha$ is only linear in the dimensionality $p$ and quasi-polynomial in other terms. Then, we extend the result to any $1$-Lipschitz generalized linear convex loss functions by showing that every such function can be approximated by a linear combination of hinge loss functions and some linear functions. Finally, we apply our technique to the Euclidean median problem and show that its sample complexity needs only to be quasi-polynomial in $p$, which is the first result with a sub-exponential sample complexity in $p$ for non-generalized linear loss functions. Our results are based on a technique, called polynomial of inner product approximation, which may be applicable to other problems.

            
            </p></div> </br> <strong>Di Wang</strong>, <a href="http://www.cse.psu.edu/~ads22/">Adam Smith</a>  and  Jinhui Xu. </br>
            The 30th International Conference on Algorithmic Learning Theory (ALT 2019).
            </li>

        </br>
        <li> <i>Empirical Risk Minimization in Non-interactive Local Differential Privacy Revisited.</i> <a href="papers/NeurIPS2018_NLDP.pdf"><img src="pdf_icon.gif" class="smallpadleft"/></a> [<a href="http://papers.nips.cc/paper/7375-empirical-risk-minimization-in-non-interactive-local-differential-privacy-revisited">Link</a>] 
            Abstract<a href="#NeurIPS2018_NLDP" id="4_arrows" class="arrows" onclick="expand_collapse('4');">&#9660</a>
            <div id="4" style="display:none;"><p>In this paper, we revisit the Empirical Risk Minimization problem in the non-interactive local model of differential privacy. In the case of constant or low dimensions ($p\ll n$), we first show that if the  loss function is $(\infty, T)$-smooth,  we can avoid a dependence of the  sample complexity, to achieve error $\alpha$, on the exponential of the dimensionality $p$ with base $1/\alpha$  (i.e., $\alpha^{-p}$),
                which answers a question in (Smith et al 2017).  Our approach is based on polynomial approximation. Then, we propose player-efficient algorithms with $1$-bit communication complexity and $O(1)$ computation cost for each player. The error bound is asymptotically the same as the original one. With some additional assumptions, we also give an efficient algorithm for the server. 
                In the case of high dimensions ($n\ll p$),
               we show that if the loss function is a convex generalized linear function,  the error  can be bounded by using the Gaussian width of the constrained set, instead of $p$, which improves the one in    
                 Smith et al.
                 Our techniques can be extended to some related problems, such as $k$-way marginal queries and smooth queries. </p></div> </br> 
                 <strong>Di Wang</strong>, <a href="http://www.acsu.buffalo.edu/~gaboardi/">Marco Gaboardi</a> and Jinhui Xu. </br>
                 
            Conference on Neural Information Processing Systems (NIPS/NeurIPS), 2018.
            
            </li>
</br>
    </li>
    <li> <i>Differentially Private Empirical Risk Minimization Revisited: Faster and More General.</i> <a href="papers/NeurIPS2017_DPERM.pdf"><img src="pdf_icon.gif" class="smallpadleft"/></a> [<a href="http://papers.nips.cc/paper/6865-differentially-private-empirical-risk-minimization-revisited-faster-and-more-general">Link</a>] Abstract<a href="#NeurIPS2017_DPERM" id="1_arrows" class="arrows" onclick="expand_collapse('1');">&#9660</a>
        <div id="1" style="display:none;"><p>In this paper we study the differentially private Empirical Risk Minimization (ERM) problem in different settings. For smooth (strongly) convex loss function with or without (non)-smooth regularization, we give algorithms that achieve either optimal or near optimal utility bounds with less gradient complexity compared with previous work.  For ERM with smooth convex loss function in high-dimensional ($p\gg n$) setting, we give an algorithm which achieves the upper bound with less gradient complexity than previous ones. At last, we generalize the expected excess empirical risk from convex loss functions to non-convex ones satisfying the Polyak-Lojasiewicz condition and give a tighter upper bound on   
            the utility than the one in (Zhang et al 2017).
        </p></div> </br> 
        <strong>Di Wang</strong>, <a href="https://dblp.org/pers/y/Ye:Minwei.html">Minwei Ye</a> and <a href="
        https://www.cse.buffalo.edu//~jinhui/">Jinhui Xu</a>. </br>
        Conference on Neural
        Information Processing Systems (NIPS/NeurIPS), 2017.

        
        </li>



</ol>

<hr>
<h3> <a name="teach">Teaching</a> </h3>
<ul>
    <li>
        Instructor
    </li>
<ul>
    <li>Short Course: Selected Topics in Private Machine Learning and Statistics, January 2021 @ECNU.</li>
    <li> CSE 474/574: Introduction to Machine Learning, Summer 2019 @SUNY at Buffalo.</li>
</ul>
</ul>
<ul>
<li>Teaching assistant:</li>
<ul>
<li> CSE 474/574 Introduction to Machine Learning, Spring 2018 @SUNY at Buffalo.  </li>
<li> CSE 431/531 Analysis of Algorithm, Fall 2017, Spring 2017, Fall 2016, Spring 2016  @SUNY at Buffalo.
    </li>
    <li>
            CSE 115 Introduction to Computer Science for Majors I, Fall 2015 @ @SUNY at Buffalo.

    </li>
<li> MATH 1229A Methods of Matrix Algebra, Summer 2015, Spring 2015 @ UWO. </li>
<li> ATH 1225B Methods of Calculus, Fall 2014 @ UWO.  </li>
</ul>
</ul>

<hr>
<h3> <a name="talks">Invited Talks</a> </h3>
<ul>
    <li>School of Cyber Science and Technology, Zhejiang University</li></br>
    <li>School of Computing and Information Systems, University of Melbourne</li></br>
    <li>Department of Computer Science and Engineering, Chinese University of Hong Kong</li></br>
    <li>Department of Computer Science, Dalhousie University</li></br>
    <li>CISPA-Helmholtz Center for Information Security</li></br>
    <li>Department of Computing, Hong Kong Polytechnic University</li></br>
    <li>Department of Computer Science, University of Memphis</li></br>
    <li>School of Computer Science, University of Sydney</li></br>
    <li>Department of Computing, Imperial College London</li></br>
    <li>Department of Computer Science, University College London</li></br>
    <li>King Abdullah University of Science and Technology</li></br>
    <li>Department of Computing and Software, McMaster University</li></br>
    <li>School of Computer Science, University of Birmingham</li></br>
    <li>Department of Computer Science, University of Warwick</li></br>
    <li>Department of Computer Science, City University of Hong Kong</li></br>
    <li>School of Information System, Singapore Management University</li></br>
    <li>Department of Computer Science and Engineering, Hong Kong University of Science and Technology</li></br>
    <li>Department of Computer Science, University of Surrey</li></br>
    <li>Department of Computer Science, McGill University</li></br>
    <li>School of Computer Sicence, University of Science and Technology China</li></br>
    <li>School of Computer Science, Nanjing University </li></br>
    <li>Department of Computer Science, University of Alberta</li></br>

</ul>

